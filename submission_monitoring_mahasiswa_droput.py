# -*- coding: utf-8 -*-
"""submission-monitoring-mahasiswa-droput

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XtH37fgp-T1WdC_feIlttKv-9G0n-Su3

# Proyek Akhir: Menyelesaikan Permasalahan Perusahaan Edutech

- Nama: Hanna Febriani Sutarman
- Email:hannafebriani675@gmail.com
- Id Dicoding: hannafebriani

## Persiapan
"""

!pip install gdown
!pip install imbalanced-learn

"""### Menyiapkan library yang dibutuhkan"""

import gdown
import pandas as pd
from sklearn.metrics import classification_report, accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import RandomizedSearchCV
from sklearn.model_selection import train_test_split
from google.colab import files
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import SelectFromModel
import seaborn as sns
import matplotlib.pyplot as plt
import joblib

"""### Menyiapkan data yang akan diguankan"""

file_id = '15-3xDnVMR0USg-MnR14iAsLIjniwMXVU'
gdown.download(f'https://drive.google.com/uc?id={file_id}', quiet=False)

"""## Data Understanding
Memahami data yang akan digunakan
"""

df = pd.read_csv('data.csv', sep=';')
df.info()
df.head()

"""**Insights:**

Data terdiri dari 4424 baris dan 37 kolom

## EDA
Melakukan eksplorasi data untuk melihat insight pada data

1. Mengecek deskripsi fitur numerik
"""

df.describe()

"""2. Distribusi status mahasiswa"""

df['Status'].value_counts()
df['Status'].value_counts(normalize=True)
df['Status'].value_counts().plot(kind='bar', title='Distribusi Status Mahasiswa')

"""3. Distribusi Status Mahasiswa berdasarkan Umur"""

# Distribusi berdasar umur
top_ages = df['Age_at_enrollment'].value_counts().nlargest(10).index

filtered_df = df[df['Age_at_enrollment'].isin(top_ages)]

plt.figure(figsize=(12, 6))
sns.countplot(y='Age_at_enrollment', hue='Status', data=filtered_df, order=top_ages)
plt.title('Distribusi Status Mahasiswa berdasarkan 10 Umur Masuk Terbanyak')
plt.xlabel('Jumlah Mahasiswa')
plt.ylabel('Umur Masuk')
plt.show()

"""4. Membandingkan fitur penting terhadap Status
Tujuan: Apakah Admission_grade, Tuition_fees_up_to_date, dan Curricular_units_1st_sem_grade
"""

sns.boxplot(x='Status', y='Admission_grade', data=df)
sns.countplot(x='Status', hue='Tuition_fees_up_to_date', data=df)
sns.boxplot(x='Status', y='Curricular_units_1st_sem_grade', data=df)

"""5. Analisis Faktor Ekonomi Makro Unemplyement rate"""

sns.boxplot(x='Status', y='Unemployment_rate', data=df)

"""**Insights:**
- Deskripsi Fitur Numerik:
Nilai-nilai pada fitur numerik terlihat wajar dan tidak menunjukkan adanya outlier ekstrem atau nilai yang mencurigakan.

- Distribusi Status Mahasiswa:
Mayoritas mahasiswa memiliki status Graduate, disusul oleh Dropout dan Enrolled. Ini menunjukkan bahwa sebagian besar mahasiswa berhasil menyelesaikan studinya, tetapi angka dropout tetap signifikan.

- Grafik mahasiswa yang paling banyak drop out berdasarkan umur masuk kuliah pada 19 tahun


- Fitur yang Mempengaruhi Dropout:
Beberapa fitur memiliki korelasi visual yang cukup kuat terhadap status mahasiswa, di antaranya:

- Admission Grade: Mahasiswa dengan nilai awal yang rendah cenderung memiliki risiko dropout lebih tinggi.

- Tuition Fees Up to Date: Mahasiswa yang memiliki tunggakan pembayaran lebih banyak ditemukan pada kelompok dropout.

- Curricular Units 1st Grade Approved: Jumlah mata kuliah yang lulus pada tahun pertama berbanding lurus dengan keberhasilan menyelesaikan studi.

- Faktor Eksternal (Ekonomi):
Employment Rate (tingkat pekerjaan di negara) tampak berkaitan dengan angka dropout. Saat tingkat pengangguran tinggi, kemungkinan dropout cenderung meningkatâ€”mungkin karena tekanan finansial atau gangguan eksternal lainnya.

## Data Preparation / Preprocessing
Melakukan data preparation dan preprocessing untuk membersihkan data sebelum modelling

1. Mengecek Missing Value
"""

df

df.isnull().sum().sort_values(ascending=False)

"""2. Menangani outlier"""

num_cols = [
    'Tuition_fees_up_to_date',
    'Age_at_enrollment',
    'Previous_qualification_grade',
    'Curricular_units_1st_sem_enrolled',
    'Curricular_units_1st_sem_evaluations',
    'Curricular_units_1st_sem_credited',
    'Curricular_units_1st_sem_approved',
    'Curricular_units_1st_sem_grade',
    'Curricular_units_1st_sem_without_evaluations',
    'Curricular_units_2nd_sem_credited',
    'Curricular_units_2nd_sem_enrolled',
    'Curricular_units_2nd_sem_evaluations',
    'Curricular_units_2nd_sem_approved',
    'Curricular_units_2nd_sem_grade',
    'Curricular_units_2nd_sem_without_evaluations',
    'Unemployment_rate',
    'Inflation_rate',
    'GDP'
]

Q1 = df[num_cols].quantile(0.25)
Q3 = df[num_cols].quantile(0.75)
IQR = Q3 - Q1

outliers_iqr = ((df[num_cols] < (Q1 - 1.5 * IQR)) | (df[num_cols] > (Q3 + 1.5 * IQR)))
print(outliers_iqr.sum())

"""3. Encode kolom target Status"""

original_df = df.copy()
status_map = {'Graduate': 1, 'Dropout': 2, 'Enrolled': 0}
df['Status'] = df['Status'].map(status_map)
df['Status']

"""4. Memisahkan fitur dan target"""

X = df.drop('Status', axis=1)
y = df['Status']

X

y

"""5. Memisahkan Train-Test Split"""

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
print(X_train.shape)
print(X_test.shape)

"""6. Melakukan Feature selection"""

rf = RandomForestClassifier(random_state=42)
rf.fit(X_train, y_train)

top_features = pd.DataFrame({
                             'Feature': X_train.columns,
                             'Importance': rf.feature_importances_
}).sort_values(by='Importance', ascending=False)
top_features

selected_features = top_features[top_features['Importance'] > 0.035]['Feature'].tolist()
print(f"Selected {len(selected_features)} features:", selected_features)

X_train_selected = X_train[selected_features]
X_test_selected = X_test[selected_features]

X_train_selected.head()

X_test_selected.head()

y_train.head()

y_test.head()

print("Shape of X_train_selected: ", X_train_selected.shape)
print("Shape of X_test_selected: ", X_test_selected.shape)
print("Shape of y_train: ", y_train.shape)
print("Shape of y_test: ", y_test.shape)

"""7. Melakukan Feature Scaling"""

X_train = X_train.reset_index(drop=True)
X_test = X_test.reset_index(drop=True)

features_to_scale = [
    'Curricular_units_2nd_sem_approved',
    'Curricular_units_2nd_sem_grade',
    'Curricular_units_1st_sem_approved',
    'Curricular_units_1st_sem_grade',
    'Admission_grade',
    'Curricular_units_2nd_sem_evaluations',
    'Age_at_enrollment',
    'Previous_qualification_grade',
    'Curricular_units_1st_sem_evaluations'
]

features_not_scaled = [
    'Tuition_fees_up_to_date'
]

X_train_to_scale = X_train[features_to_scale]
X_test_to_scale = X_test[features_to_scale]

X_train_not_scaled = X_train[features_not_scaled]
X_test_not_scaled = X_test[features_not_scaled]

# Scaling hanya fitur numerik
scaler = StandardScaler()
X_train_scaled_part = scaler.fit_transform(X_train_to_scale)
X_test_scaled_part = scaler.transform(X_test_to_scale)

# Konversi hasil scaling ke DataFrame lagi
X_train_scaled_df = pd.DataFrame(X_train_scaled_part, columns=features_to_scale)
X_test_scaled_df = pd.DataFrame(X_test_scaled_part, columns=features_to_scale)

# Gabungkan kembali dengan fitur kategori
X_train_scaled = pd.concat([X_train_scaled_df, X_train_not_scaled], axis=1)
X_test_scaled = pd.concat([X_test_scaled_df, X_test_not_scaled], axis=1)

# Urutkan kolom sesuai urutan semula:
X_train_scaled = X_train_scaled[X_train_to_scale.columns.tolist() + X_train_not_scaled.columns.tolist()]
X_test_scaled = X_test_scaled[X_test_to_scale.columns.tolist() + X_test_not_scaled.columns.tolist()]

print(X_train_scaled.shape)
print(X_test_scaled.shape)

print(X_train_scaled.isna().sum())
print(X_test_scaled.isna().sum())

X_train_scaled

X_test_scaled

"""**Insights:**
- Tidak ada missing value pada data
- Outlier pada fitur numerik tidak ditangani atau dibiarkan saja, karena data tersebut masih penting

- Encoding Data Kategorikal
Kolom Status yang sebelumnya bertipe object telah diubah menjadi tipe numerik agar dapat digunakan dalam model machine learning.

- Target Variable
Kolom Status dipilih sebagai target untuk prediksi dropout.

- Train-Test Split
Dataset dibagi menjadi data pelatihan dan data pengujian untuk menghindari data leakage dan memastikan generalisasi model.

- Feature Selection
Seleksi fitur dilakukan menggunakan Random Forest.
Jumlah fitur awal: 36
Jumlah fitur terpilih: 10
Fitur yang dipilih: ['Curricular_units_2nd_sem_approved', 'Curricular_units_2nd_sem_grade', 'Curricular_units_1st_sem_approved', 'Curricular_units_1st_sem_grade', 'Admission_grade', 'Curricular_units_2nd_sem_evaluations', 'Tuition_fees_up_to_date', 'Age_at_enrollment', 'Previous_qualification_grade', 'Curricular_units_1st_sem_evaluations']

- Proses scaling pada fitur numerik dilakukan menggunakan StandardScaler untuk menstandarisasi data dan meningkatkan performa model.

## Modeling
"""

# Buat model RF dasar
rf = RandomForestClassifier(random_state=42)

"""**Insights:**

Modelling random forest lebih robust terhadap outlier

## Evaluation
"""

# Parameter
param_dist = {
    'n_estimators': [100, 200, 300, 400, 500],
    'max_depth': [None, 5, 10, 15, 20],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'max_features': ['sqrt', 'log2']
}

# RandomizedSearchCV dengan 5 fold cross-validation
random_search = RandomizedSearchCV(
    estimator=rf,
    param_distributions=param_dist,
    n_iter=20,
    scoring='accuracy',
    cv=5,
    verbose=2,
    random_state=42,
    n_jobs=-1
)

# Fit ke data training
random_search.fit(X_train_scaled, y_train)

# Best estimator dan parameter
print("Best parameters:", random_search.best_params_)

# Prediksi dan evaluasi
best_rf = random_search.best_estimator_
y_pred = best_rf.predict(X_test_scaled)
print(f"Random Forest Accuracy: {accuracy_score(y_test, y_pred):.4f}")
print(classification_report(y_test, y_pred))

"""**Insights:**

- Memakai hyperparameter tunning untuk meningkatkan akurasi
- Di dapatkan akurasi 0.77

## Simpan Model
"""

import joblib
joblib.dump(best_rf, 'model_rf.pkl')
joblib.dump(scaler, 'scaler.pkl')
joblib.dump(selected_features, 'selected_features.pkl')

selected_features

"""## Inference

1. Contoh inference graduate
"""

model = joblib.load('model_rf.pkl')
scaler = joblib.load('scaler.pkl')

selected_features = list(model.feature_names_in_)

features_to_scale = [
    'Curricular_units_2nd_sem_approved',
    'Curricular_units_2nd_sem_grade',
    'Curricular_units_1st_sem_approved',
    'Curricular_units_1st_sem_grade',
    'Admission_grade',
    'Curricular_units_2nd_sem_evaluations',
    'Age_at_enrollment',
    'Previous_qualification_grade',
    'Curricular_units_1st_sem_evaluations'
]
features_not_scaled = ['Tuition_fees_up_to_date']

sample_input = pd.DataFrame([{
    'Curricular_units_2nd_sem_approved': 5,
    'Curricular_units_2nd_sem_grade': 13.2,
    'Curricular_units_1st_sem_approved': 6,
    'Curricular_units_1st_sem_grade': 14.8,
    'Admission_grade': 165.0,
    'Curricular_units_2nd_sem_evaluations': 7,
    'Tuition_fees_up_to_date': 1,  # 1 = Ya, 0 = Tidak
    'Age_at_enrollment': 18,
    'Previous_qualification_grade': 150.0,
    'Curricular_units_1st_sem_evaluations': 8
}])

for col in selected_features:
  if col not in sample_input.columns:
    sample_input[col] = 0

features_to_scale_filtered = [f for f in selected_features if f in features_to_scale]
features_not_scaled_filtered = [f for f in selected_features if f in features_not_scaled]

X_to_scale = sample_input[features_to_scale_filtered]
X_not_scaled = sample_input[features_not_scaled_filtered]

X_scaled_part = scaler.transform(X_to_scale)
X_scaled_df = pd.DataFrame(X_scaled_part, columns=features_to_scale_filtered)

sample_final = pd.concat([X_scaled_df, X_not_scaled], axis=1)

sample_final = sample_final[selected_features]

pred = model.predict(sample_final)[0]
probs = model.predict_proba(sample_final)[0]

status_map_reverse = {0: "Enrolled", 1: "Graduate", 2: "Dropout"}

print("Predicted Status Mahasiswa:", status_map_reverse[pred])
for i, prob in enumerate(probs):
    print(f"Probability of {status_map_reverse[i]}: {prob:.4f}")

"""2. Contoh inference drop out"""

import pandas as pd
import joblib

model = joblib.load('model_rf.pkl')
scaler = joblib.load('scaler.pkl')

selected_features = list(model.feature_names_in_)

features_to_scale = [
    'Curricular_units_2nd_sem_approved',
    'Curricular_units_2nd_sem_grade',
    'Curricular_units_1st_sem_approved',
    'Curricular_units_1st_sem_grade',
    'Admission_grade',
    'Curricular_units_2nd_sem_evaluations',
    'Age_at_enrollment',
    'Previous_qualification_grade',
    'Curricular_units_1st_sem_evaluations'
]
features_not_scaled = ['Tuition_fees_up_to_date']

sample_input = pd.DataFrame([{
    'Curricular_units_2nd_sem_approved': 0,
    'Curricular_units_2nd_sem_grade': 9,
    'Curricular_units_1st_sem_approved': 10,
    'Curricular_units_1st_sem_grade': 10,
    'Admission_grade': 135.0,
    'Curricular_units_2nd_sem_evaluations': 7,
    'Tuition_fees_up_to_date': 0,  # 1 = Ya, 0 = Tidak
    'Age_at_enrollment': 22,
    'Previous_qualification_grade': 70.0,
    'Curricular_units_1st_sem_evaluations': 5
}])

for col in selected_features:
  if col not in sample_input.columns:
    sample_input[col] = 0

features_to_scale_filtered = [f for f in selected_features if f in features_to_scale]
features_not_scaled_filtered = [f for f in selected_features if f in features_not_scaled]

X_to_scale = sample_input[features_to_scale_filtered]
X_not_scaled = sample_input[features_not_scaled_filtered]

X_scaled_part = scaler.transform(X_to_scale)
X_scaled_df = pd.DataFrame(X_scaled_part, columns=features_to_scale_filtered)

sample_final = pd.concat([X_scaled_df, X_not_scaled], axis=1)

sample_final = sample_final[selected_features]

pred = model.predict(sample_final)[0]
probs = model.predict_proba(sample_final)[0]

status_map_reverse = {0: "Enrolled", 1: "Graduate", 2: "Dropout"}

print("Predicted Status Mahasiswa:", status_map_reverse[pred])
for i, prob in enumerate(probs):
    print(f"Probability of {status_map_reverse[i]}: {prob:.4f}")

"""Mapping untuk dashboard"""

# Salin dari original_df sebelum scaling
df_dashboard = original_df[selected_features + ['Status']].copy()

# Mapping Tuition Fees
df_dashboard['Tuition_fees_up_to_date'] = df_dashboard['Tuition_fees_up_to_date'].map({0: 'No', 1: 'Yes'})


print(df_dashboard['Status'].unique())

df_dashboard.head()

# Simpan ke file
df_dashboard.to_csv('dashboard_data.csv', index=False)

files.download("dashboard_data.csv")

print("sudah tersimpan")